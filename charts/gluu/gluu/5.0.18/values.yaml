# -- Only used by the installer. These settings do not affect nor are used by the chart
installer-settings:
  currentVersion: ""
  acceptLicense: ""
  namespace: ""
  releaseName: ""
  nginxIngress:
    releaseName: ""
    namespace: ""
  nodes:
    names: ""
    zones: ""
    ips: ""
  images:
    edit: ""
  aws:
    lbType: ""
    arn:
      enabled: ""
      arnAcmCert: ""
    vpcCidr: "0.0.0.0/0"
  couchbase:
    clusterName: ""
    namespace: ""
    lowResourceInstall: ""
    install: ""
    customFileOverride: ""
    backup:
      incrementalSchedule: ""
      fullSchedule: ""
      retentionTime: ""
      storageSize: ""
    # Couchbase cert related keys
    subjectAlternativeName: ""
    commonName: ""
    # Couchbase cluster yaml generator keys
    totalNumberOfExpectedUsers: ""
    totalNumberOfExpectedTransactionsPerSec: ""
    volumeType: ""
  volumeProvisionStrategy: ""
  ldap:
    backup:
      fullSchedule: ""
  postgres:
    install: ""
    namespace: ""
  sql:
    install: ""
    namespace: ""
  google:
    useSecretManager: ""
  redis:
    install: ""
    namespace: ""
  openbanking:
    hasCnObTransportTrustStore: false
    cnObTransportTrustStoreP12password: ""
  confirmSettings: false

# --  Admin GUI for configuration of the auth-server
admin-ui:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/gluufederation/flex/admin-ui
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 2000m
      # -- Memory limit.
      memory: 2000Mi
    requests:
      # -- CPU request.
      cpu: 2000m
      # -- Memory request.
      memory: 2000Mi
  # -- Configure the liveness healthcheck for the admin ui if needed.
  livenessProbe:
    tcpSocket:
      port: 8080
    initialDelaySeconds: 60
    timeoutSeconds: 5
    periodSeconds: 25
    failureThreshold: 20
  # -- Configure the readiness healthcheck for the admin ui if needed.
  readinessProbe:
    tcpSocket:
      port: 8080
    initialDelaySeconds: 60
    timeoutSeconds: 5
    periodSeconds: 25
    failureThreshold: 20
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}
  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- OAuth Authorization Server, the OpenID Connect Provider, the UMA Authorization Server--this is the main Internet facing component of Gluu. It's the service that returns tokens, JWT's and identity assertions. This service must be Internet facing.
auth-server:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/auth-server
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 2500m
      # -- Memory limit.
      memory: 2500Mi
    requests:
      # -- CPU request.
      cpu: 2500m
      # -- Memory request.
      memory: 2500Mi
  # -- Configure the liveness healthcheck for the auth server if needed.
  livenessProbe:
    # -- Executes the python3 healthcheck.
    # https://github.com/JanssenProject/docker-jans-auth-server/blob/master/scripts/healthcheck.py
    exec:
      command:
        - python3
        - /app/scripts/healthcheck.py
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
  # -- Configure the readiness healthcheck for the auth server if needed.
  # https://github.com/JanssenProject/docker-jans-auth-server/blob/master/scripts/healthcheck.py
  readinessProbe:
    exec:
      command:
        - python3
        - /app/scripts/healthcheck.py
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}
  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Responsible for regenerating auth-keys per x hours
auth-server-key-rotation:
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/certmanager
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Auth server key rotation keys life in hours
  keysLife: 48
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 300m
      # -- Memory limit.
      memory: 300Mi
    requests:
      # -- CPU request.
      cpu: 300m
      # -- Memory request.
      memory: 300Mi
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}
  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Gluu Casa ("Casa") is a self-service web portal for end-users to manage authentication and authorization preferences for their account in a Gluu Server.
casa:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/gluufederation/flex/casa
    # -- Image  tag to use for deploying.
    tag: 5.0.0-13
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 500m
      # -- Memory limit.
      memory: 500Mi
    requests:
      # -- CPU request.
      cpu: 500m
      # -- Memory request.
      memory: 500Mi
  # -- Configure the liveness healthcheck for casa if needed.
  livenessProbe:
    httpGet:
      # -- http liveness probe endpoint
      path: /casa/health-check
      port: http-casa
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
  # -- Configure the readiness healthcheck for the casa if needed.
  readinessProbe:
    httpGet:
      # -- http readiness probe endpoint
      path: /casa/health-check
      port: http-casa
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Configuration parameters for setup and initial configuration secret and config layers used by Gluu services.
config:
  # -- Add custom normal and secret envs to the service.
  usrEnvs:
    # -- Add custom normal envs to the service.
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service.
    # variable1: value1
    secret: {}
  # -- Admin password to log in to the UI.
  adminPassword: Test1234#
  # -- City. Used for certificate creation.
  city: Austin
  configmap:
    # -- Jetty header size in bytes in the auth server
    cnJettyRequestHeaderSize: 8192
    # -- Schema name used by SQL database (default to empty-string; if using MySQL, the schema name will be resolved as the database name, whereas in PostgreSQL the schema name will be resolved as `"public"`).
    cnSqlDbSchema: ""
    # -- SQL database dialect. `mysql` or `pgsql`
    cnSqlDbDialect: mysql
    # -- SQL database host uri.
    cnSqlDbHost: my-release-mysql.default.svc.cluster.local
    # -- SQL database port.
    cnSqlDbPort: 3306
    # -- SQL database name.
    cnSqlDbName: gluu
    # -- SQL database username.
    cnSqlDbUser: gluu
    # -- SQL database timezone.
    cnSqlDbTimezone: UTC
    # -- SQL password  injected the secrets .
    cnSqldbUserPassword: Test1234#
    # -- Cache type. `NATIVE_PERSISTENCE`, `REDIS`. or `IN_MEMORY`. Defaults to `NATIVE_PERSISTENCE` .
    cnCacheType: NATIVE_PERSISTENCE
    # -- The name of the Kubernetes ConfigMap that will hold the configuration layer
    cnConfigKubernetesConfigMap: cn
    # -- The prefix of couchbase buckets. This helps with separation in between different environments and allows for the same couchbase cluster to be used by different setups of Gluu.
    cnCouchbaseBucketPrefix: jans
    # -- Couchbase certificate authority string. This must be encoded using base64. This can also be found in your couchbase UI Security > Root Certificate. In mTLS setups this is not required.
    cnCouchbaseCrt: SWFtTm90YVNlcnZpY2VBY2NvdW50Q2hhbmdlTWV0b09uZQo=
    # -- The number of replicas per index created. Please note that the number of index nodes must be one greater than the number of index replicas. That means if your couchbase cluster only has 2 index nodes you cannot place the number of replicas to be higher than 1.
    cnCouchbaseIndexNumReplica: 0
    # -- Couchbase password for the restricted user config.configmap.cnCouchbaseUser  that is often used inside the services. The password must contain one digit, one uppercase letter, one lower case letter and one symbol .
    cnCouchbasePassword: P@ssw0rd
    # -- The Couchbase super user (admin) username. This user is used during initialization only.
    cnCouchbaseSuperUser: admin
    # -- Couchbase password for the superuser config.configmap.cnCouchbaseSuperUser  that is used during the initialization process. The password must contain one digit, one uppercase letter, one lower case letter and one symbol
    cnCouchbaseSuperUserPassword: Test1234#
    # -- Couchbase URL. Used only when global.cnPersistenceType is hybrid or couchbase. This should be in FQDN format for either remote or local Couchbase clusters. The address can be an internal address inside the kubernetes cluster
    cnCouchbaseUrl: cbgluu.default.svc.cluster.local
    # -- Couchbase restricted user. Used only when global.cnPersistenceType is hybrid or couchbase.
    cnCouchbaseUser: gluu
    # [google_envs] Envs related to using Google
    # -- Service account with roles roles/secretmanager.admin base64 encoded string. This is used often inside the services to reach the configuration layer. Used only when global.configAdapterName and global.configSecretAdapter is set to google.
    cnGoogleSecretManagerServiceAccount: SWFtTm90YVNlcnZpY2VBY2NvdW50Q2hhbmdlTWV0b09uZQo=
    # -- Project id of the Google project the secret manager belongs to. Used only when global.configAdapterName and global.configSecretAdapter is set to google.
    cnGoogleProjectId: google-project-to-save-config-and-secrets-to
    # [google_spanner_envs] Envs related to using Google Secret Manager to store config and secret layer
    # -- Google Spanner ID. Used only when global.cnPersistenceType is spanner.
    cnGoogleSpannerInstanceId: ""
    # -- Google Spanner Database ID. Used only when global.cnPersistenceType is spanner.
    cnGoogleSpannerDatabaseId: ""
    # [google_spanner_envs] END
    # [google_secret_manager_envs] Envs related to using Google Secret Manager to store config and secret layer
    # -- Secret version to be used for secret configuration. Defaults to latest and should normally always stay that way. Used only when global.configAdapterName and global.configSecretAdapter is set to google.
    cnGoogleSecretVersionId: "latest"
    # -- Prefix for Gluu secret in Google Secret Manager. Defaults to gluu. If left gluu-secret secret will be created. Used only when global.configAdapterName and global.configSecretAdapter is set to google.
    cnGoogleSecretNamePrefix: gluu
    # [google_secret_manager_envs] END
    # [google_envs] END
    # [aws_envs] Envs related to using AWS
    # [aws_secret_manager_envs]
    # AWS Access key id  that belong to a user/id with SecretsManagerReadWrite policy
    cnAwsAccessKeyId: ""
    # AWS Secret Access key that belong to a user/id with SecretsManagerReadWrite policy
    cnAwsSecretAccessKey: ""
    #The URL of AWS secretsmanager service (if omitted, will use the one in the specified default region. Example: https://secretsmanager.us-west-1.amazonaws.com). Used only when global.configAdapterName and global.configSecretAdapter is set to aws.
    cnAwsSecretsEndpointUrl: ""
    # The prefix name of the secrets. Used only when global.configAdapterName and global.configSecretAdapter is set to aws.
    cnAwsSecretsNamePrefix: gluu
    # The default AWS Region to use, for example, `us-west-1` or `us-west-2`.
    cnAwsDefaultRegion: us-west-1
    # The aws named profile to use. Has to be created first. This is a sensible default and it's good to leave it as is. https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html
    cnAwsProfile: gluu
    # Example replicated region [{"Region": "us-west-1"}, {"Region": "us-west-2"}]
    cnAwsSecretsReplicaRegions: []
    # [aws_secret_manager_envs] END
    # [aws_envs] END
    # -- OpenDJ internal address. Leave as default. Used when `global.cnPersistenceType` is set to `ldap`.
    cnLdapUrl: "opendj:1636"
    # -- Value passed to Java option -XX:MaxRAMPercentage
    cnMaxRamPercent: "75.0"
    # -- SCIM protection mode OAUTH|TEST|UMA
    cnScimProtectionMode: "OAUTH"
    # -- Specify data that should be saved in LDAP (one of default, user, cache, site, token, or session; default to default). Note this environment only takes effect when `global.cnPersistenceType`  is set to `hybrid`.
    #{
    #  "default": "<couchbase|ldap|spanner|sql>",
    #  "user": "<couchbase|ldap|spanner|sql>",
    #  "site": "<couchbase|ldap|spanner|sql>",
    #  "cache": "<couchbase|ldap|spanner|sql>",
    #  "token": "<couchbase|ldap|spanner|sql>",
    #  "session": "<couchbase|ldap|spanner|sql>",
    #}
    cnPersistenceHybridMapping: "{}"
    # -- Redis Sentinel Group. Often set when `config.configmap.cnRedisType` is set to `SENTINEL`. Can be used when  `config.configmap.cnCacheType` is set to `REDIS`.
    cnRedisSentinelGroup: ""
    # -- Redis SSL truststore. Optional. Can be used when  `config.configmap.cnCacheType` is set to `REDIS`.
    cnRedisSslTruststore: ""
    # -- Redis service type. `STANDALONE` or `CLUSTER`. Can be used when  `config.configmap.cnCacheType` is set to `REDIS`.
    cnRedisType: STANDALONE
    # -- Redis URL and port number <url>:<port>. Can be used when  `config.configmap.cnCacheType` is set to `REDIS`.
    cnRedisUrl: "redis.redis.svc.cluster.local:6379"
    # -- Boolean to use SSL in Redis. Can be used when  `config.configmap.cnCacheType` is set to `REDIS`.
    cnRedisUseSsl: false
    # -- Kubernetes secret name holding configuration keys. Used when global.configSecretAdapter is set to kubernetes which is the default.
    cnSecretKubernetesSecret: cn
    # -- Load balancer address for AWS if the FQDN is not registered.
    lbAddr: ""
  # -- Country code. Used for certificate creation.
  countryCode: US
  # -- Email address of the administrator usually. Used for certificate creation.
  email: support@gluu.org
  image:
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/configurator
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- LDAP admin password if OpenDJ is used for persistence.
  ldapPassword: P@ssw0rds
  # -- Organization name. Used for certificate creation.
  orgName: Gluu
  # -- Redis admin password if `config.configmap.cnCacheType` is set to `REDIS`.
  redisPassword: P@assw0rd
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 300m
      # -- Memory limit.
      memory: 300Mi
    requests:
      # -- CPU request.
      cpu: 300m
      # -- Memory request.
      memory: 300Mi
  # -- State code. Used for certificate creation.
  state: TX
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  # -- CE to CN Migration section
  migration:
   # -- Boolean flag to enable migration from CE
   enabled: false
   # -- Directory holding all migration files
   migrationDir: /ce-migration
   # -- migration data-format depending on persistence backend.
   # Supported data formats are ldif, couchbase+json, spanner+avro, postgresql+json, and mysql+json.
   migrationDataFormat: ldif

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Config Api endpoints can be used to configure the auth-server, which is an open-source OpenID Connect Provider (OP) and UMA Authorization Server (AS).
config-api:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/config-api
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 1000m
      # -- Memory limit.
      memory: 1000Mi
    requests:
      # -- CPU request.
      cpu: 1000m
      # -- Memory request.
      memory: 1000Mi
  # -- Configure the liveness healthcheck for the auth server if needed.
  livenessProbe:
    # -- http liveness probe endpoint
    httpGet:
      path: /jans-config-api/api/v1/health/live
      port: 8074
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
  readinessProbe:
    # -- http readiness probe endpoint
    httpGet:
      path: jans-config-api/api/v1/health/ready
      port: 8074
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- FIDO 2.0 (FIDO2) is an open authentication standard that enables leveraging common devices to authenticate to online services in both mobile and desktop environments.
fido2:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/fido2
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 500m
      # -- Memory limit.
      memory: 500Mi
    requests:
      # -- CPU request.
      cpu: 500m
      # -- Memory request.
      memory: 500Mi
  service:
    # -- The name of the fido2 port within the fido2 service. Please keep it as default.
    name: http-fido2
    # -- Port of the fido2 service. Please keep it as default.
    port: 8080
  # -- Configure the liveness healthcheck for the fido2 if needed.
  livenessProbe:
    # -- http liveness probe endpoint
    httpGet:
      path: /jans-fido2/sys/health-check
      port: http-fido2
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
  # -- Configure the readiness healthcheck for the fido2 if needed.
  readinessProbe:
    httpGet:
      path: /jans-fido2/sys/health-check
      port: http-fido2
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Parameters used globally across all services helm charts.
global:
  # -- Add custom normal and secret envs to the service.
  # Envs defined in global.userEnvs will be globally available to all services
  usrEnvs:
    # -- Add custom normal envs to the service.
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service.
    # variable1: value1
    secret: {}
  alb:
    # -- Activates ALB ingress
    ingress: false
  # -- Your organization needs to register with Gluu to trial Flex, after which you are issued a JWT placed here in which you can use to install. This must be base64 encoded.
  licenseSsa: ""
  admin-ui:
    # -- Boolean flag to enable/disable the admin-ui chart and admin ui config api plugin.
    enabled: true
    # -- Name of the admin-ui service. Please keep it as default.
    adminUiServiceName: admin-ui
    ingress:
      # -- Enable Admin UI endpoints in either istio or nginx ingress depending on users choice
      adminUiEnabled: false

  auth-server:
    # -- Name of the auth-server service. Please keep it as default.
    authServerServiceName: auth-server
    # -- Boolean flag to enable/disable auth-server chart. You should never set this to false.
    enabled: true
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    appLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e auth-server-script ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- jans-auth.log target
      authLogTarget: "STDOUT"
      # -- jans-auth.log level
      authLogLevel: "INFO"
      # -- http_request_response.log target
      httpLogTarget: "FILE"
      # -- http_request_response.log level
      httpLogLevel: "INFO"
      # -- jans-auth_persistence.log target
      persistenceLogTarget: "FILE"
      # -- jans-auth_persistence.log level
      persistenceLogLevel: "INFO"
      # -- jans-auth_persistence_duration.log target
      persistenceDurationLogTarget: "FILE"
      # -- jans-auth_persistence_duration.log level
      persistenceDurationLogLevel: "INFO"
      # -- jans-auth_persistence_ldap_statistics.log target
      ldapStatsLogTarget: "FILE"
      # -- jans-auth_persistence_ldap_statistics.log level
      ldapStatsLogLevel: "INFO"
      # -- jans-auth_script.log target
      scriptLogTarget: "FILE"
      # -- jans-auth_script.log level
      scriptLogLevel: "INFO"
      # -- jans-auth_script.log target
      auditStatsLogTarget: "FILE"
      # -- jans-auth_audit.log level
      auditStatsLogLevel: "INFO"
    # -- space-separated key algorithm for signing (default to `RS256 RS384 RS512 ES256 ES384 ES512 PS256 PS384 PS512`)
    authSigKeys: "RS256 RS384 RS512 ES256 ES384 ES512 PS256 PS384 PS512"
    # -- space-separated key algorithm for encryption (default to `RSA1_5 RSA-OAEP`)
    authEncKeys: "RSA1_5 RSA-OAEP"
    # -- Enable endpoints in either istio or nginx ingress depending on users choice
    ingress:
      # -- Enable Auth server endpoints /jans-auth
      authServerEnabled: true
      # -- Enable endpoint /.well-known/openid-configuration
      openidConfigEnabled: true
      # -- Enable endpoint /device-code
      deviceCodeEnabled: true
      # -- Enable endpoint /firebase-messaging-sw.js
      firebaseMessagingEnabled: true
      # -- Enable endpoint /.well-known/uma2-configuration
      uma2ConfigEnabled: true
      # -- Enable endpoint /.well-known/webfinger
      webfingerEnabled: true
      # -- Enable endpoint /.well-known/simple-web-discovery
      webdiscoveryEnabled: true
      # -- Enable endpoint /.well-known/fido-configuration
      u2fConfigEnabled: true
      # -- Enable mTLS on Auth server endpoint /jans-auth/restv1/token. Currently not working in Istio.
      authServerProtectedToken: false
      # -- Enable mTLS onn Auth server endpoint /jans-auth/restv1/register. Currently not working in Istio.
      authServerProtectedRegister: false
  auth-server-key-rotation:
    # -- Boolean flag to enable/disable the auth-server-key rotation cronjob chart.
    enabled: false
  # -- Volume storage type if using AWS volumes.
  awsStorageType: io1
  # -- Volume storage type if using Azure disks.
  azureStorageAccountType: Standard_LRS
  # -- Azure storage kind if using Azure disks
  azureStorageKind: Managed
  casa:
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    appLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e casa ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- casa.log target
      casaLogTarget: "STDOUT"
      # -- casa.log level
      casaLogLevel: "INFO"
      # -- casa timer log target
      timerLogTarget: "FILE"
      # -- casa timer log level
      timerLogLevel: "INFO"
    # -- Name of the casa service. Please keep it as default.
    casaServiceName: casa
    # -- Boolean flag to enable/disable the casa chart.
    enabled: true
    # -- Enable endpoints in either istio or nginx ingress depending on users choice
    ingress:
      # -- Enable casa endpoints /casa
      casaEnabled: false
  cloud:
    # -- Boolean flag if enabled will strip resources requests and limits from all services.
    testEnviroment: false
  # -- Port used by Prometheus JMX agent (default to empty string). To enable Prometheus JMX agent, set the value to a number.
  cnPrometheusPort: ""
  # -- Document store type to use for shibboleth files LOCAL.
  cnDocumentStoreType: LOCAL
  # -- Persistence backend to run Gluu with ldap|couchbase|hybrid|sql|spanner.
  cnPersistenceType: sql
  # -- Open banking external signing jwks uri. Used in SSA Validation.
  cnObExtSigningJwksUri: ""
  # -- Open banking external signing jwks AS certificate authority string. Used in SSA Validation. This must be encoded using base64.. Used when `.global.cnObExtSigningJwksUri` is set.
  cnObExtSigningJwksCrt: ""
  # -- Open banking external signing jwks AS key string. Used in SSA Validation. This must be encoded using base64. Used when `.global.cnObExtSigningJwksUri` is set.
  cnObExtSigningJwksKey: ""
  # -- Open banking external signing jwks AS key passphrase to unlock provided key. This must be encoded using base64. Used when `.global.cnObExtSigningJwksUri` is set.
  cnObExtSigningJwksKeyPassPhrase: ""
  # -- Open banking external signing AS Alias. This is a kid value.Used in SSA Validation, kid used while encoding a JWT sent to token URL i.e. XkwIzWy44xWSlcWnMiEc8iq9s2G
  cnObExtSigningAlias: ""
  # -- Open banking  signing AS kid to force the AS to use a specific signing key. i.e. Wy44xWSlcWnMiEc8iq9s2G
  cnObStaticSigningKeyKid: ""
  # -- Open banking AS transport crt. Used in SSA Validation. This must be encoded using base64.
  cnObTransportCrt: ""
  # -- Open banking AS transport key. Used in SSA Validation. This must be encoded using base64.
  cnObTransportKey: ""
  # -- Open banking AS transport key passphrase to unlock AS transport key. This must be encoded using base64.
  cnObTransportKeyPassPhrase: ""
  # -- Open banking transport Alias used inside the JVM.
  cnObTransportAlias: ""
  # -- Open banking AS transport truststore crt. This is normally generated from the OB issuing CA, OB Root CA and Signing CA. Used when .global.cnObExtSigningJwksUri is set. Used in SSA Validation. This must be encoded using base64.
  cnObTransportTrustStore: ""
  config:
    # -- Boolean flag to enable/disable the configuration chart. This normally should never be false
    enabled: true
  # -- https://kubernetes.io/docs/concepts/workloads/controllers/ttlafterfinished/
  jobTtlSecondsAfterFinished: 300
  # -- The config backend adapter that will hold Gluu configuration layer. aws|google|kubernetes
  configAdapterName: kubernetes
  # -- The config backend adapter that will hold Gluu secret layer. aws|google|kubernetes
  configSecretAdapter: kubernetes
  # -- Base64 encoded service account. The sa must have roles/secretmanager.admin to use Google secrets and roles/spanner.databaseUser to use Spanner. Leave as this is a sensible default.
  cnGoogleApplicationCredentials: /etc/jans/conf/google-credentials.json
  # The location of the shared credentials file used by the client (see https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html).Leave as this is a sensible default.
  cnAwsSharedCredentialsFile: /etc/jans/conf/aws_shared_credential_file
  # The location of the config file used by the client (see https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html). Leave as this is a sensible default.
  cnAwsConfigFile: /etc/jans/conf/aws_config_file
  # The location of file contains replica regions definition (if any). This file is mostly used in primary region. Example of contents of the file: `[{"Region": "us-west-1"}]`.  Used only when global.configAdapterName and global.configSecretAdapter is set to aws. Leave as this is a sensible default.
  cnAwsSecretsReplicaRegionsFile: /etc/jans/conf/aws_secrets_replica_regions
  config-api:
    # -- Name of the config-api service. Please keep it as default.
    configApiServerServiceName: config-api
    # -- Boolean flag to enable/disable the config-api chart.
    enabled: true
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    appLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e config-api_persistence ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- configapi.log target
      configApiLogTarget: "STDOUT"
      # -- configapi.log level
      configApiLogLevel: "INFO"
      # -- config-api_persistence.log target
      persistenceLogTarget: "FILE"
      # -- config-api_persistence.log level
      persistenceLogLevel: "INFO"
      # -- config-api_persistence_duration.log target
      persistenceDurationLogTarget: "FILE"
      # -- config-api_persistence_duration.log level
      persistenceDurationLogLevel: "INFO"
      # -- config-api_persistence_ldap_statistics.log target
      ldapStatsLogTarget: "FILE"
      # -- config-api_persistence_ldap_statistics.log level
      ldapStatsLogLevel: "INFO"
      # -- config-api_script.log target
      scriptLogTarget: "FILE"
      # -- config-api_script.log level
      scriptLogLevel: "INFO"
    adminUiAppLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e config-api_persistence ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- config-api admin-ui plugin log level
      adminUiLogTarget: "FILE"
      # -- config-api admin-ui plugin log target
      adminUiLogLevel: "INFO"
      # -- config-api admin-ui plugin audit log target
      adminUiAuditLogTarget: "FILE"
      # -- config-api admin-ui plugin audit log level
      adminUiAuditLogLevel: "INFO"
    # -- Enable endpoints in either istio or nginx ingress depending on users choice
    ingress:
      # Enable config API endpoints /jans-config-api
      configApiEnabled: true
  # -- Fully qualified domain name to be used for Gluu installation. This address will be used to reach Gluu services.
  fqdn: demoexample.gluu.org
  fido2:
    # -- Name of the fido2 service. Please keep it as default.
    fido2ServiceName: fido2
    # -- Boolean flag to enable/disable the fido2 chart.
    enabled: true
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    appLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e fido2 ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- fido2.log target
      fido2LogTarget: "STDOUT"
      # -- fido2.log level
      fido2LogLevel: "INFO"
      # -- fido2_persistence.log target
      persistenceLogTarget: "FILE"
      # -- fido2_persistence.log level
      persistenceLogLevel: "INFO"
      # -- fido2_persistence_duration.log target
      persistenceDurationLogTarget: "FILE"
      # -- fido2_persistence_duration.log level
      persistenceDurationLogLevel: "INFO"
      # -- fido2_script.log target
      scriptLogTarget: "FILE"
      # -- fido2_script.log level
      scriptLogLevel: "INFO"
    # -- Enable endpoints in either istio or nginx ingress depending on users choice
    ingress:
      # -- Enable endpoint /.well-known/fido2-configuration
      fido2ConfigEnabled: false
  # -- GCE storage kind if using Google disks
  gcePdStorageType: pd-standard
  # -- Boolean flag to enable mapping global.lbIp  to global.fqdn inside pods on clouds that provide static ip for load balancers. On cloud that provide only addresses to the LB this flag will enable a script to actively scan config.configmap.lbAddr and update the hosts file inside the pods automatically.
  isFqdnRegistered: false
  istio:
    # -- Boolean flag that enables using istio side-cars with Gluu services.
    enabled: false
    # -- Boolean flag that enables using istio gateway for Gluu. This assumes istio ingress is installed and hence the LB is available.
    ingress: false
    # -- The namespace istio is deployed in. The is normally istio-system.
    namespace: istio-system
    # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
    additionalLabels: { }
    # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
    additionalAnnotations: { }
    # -- Override the gateway that can be created by default. This is used when istio ingress has already been setup and the gateway exists.
    gateways: [ ]
  # -- The Loadbalancer IP created by nginx or istio on clouds that provide static IPs. This is not needed if `global.fqdn` is globally resolvable.
  lbIp: 22.22.22.22
  nginx-ingress:
    # -- Boolean flag to enable/disable the nginx-ingress definitions chart.
    enabled: true
  opendj:
    # -- Boolean flag to enable/disable the OpenDJ  chart.
    enabled: false
    # -- Name of the OpenDJ service. Please keep it as default.
    ldapServiceName: opendj
  oxpassport:
    # -- Name of the oxPassport service. Please keep it as default.
    oxPassportServiceName: oxpassport
    # -- Boolean flag to enable/disable passport chart
    enabled: false
  oxshibboleth:
    # -- Name of the oxShibboleth service. Please keep it as default.
    oxShibbolethServiceName: oxshibboleth
    # -- Boolean flag to enable/disable the oxShibbboleth chart.
    enabled: false
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    # log levels are "OFF", "FATAL", "ERROR", "WARN", "INFO", "DEBUG", "TRACE"
    # Targets are "STDOUT" and "FILE"
    appLoggers:
      # -- idp-process.log target
      idpLogTarget: "STDOUT"
      # -- idp-process.log level
      idpLogLevel: "INFO"
      # -- idp-script.log target
      scriptLogTarget: "FILE"
      # -- idp-script.log level
      scriptLogLevel: "INFO"
      # -- idp-audit.log target
      auditStatsLogTarget: "FILE"
      # -- idp-audit.log level
      auditStatsLogLevel: "INFO"
      # -- idp-consent-audit.log target
      consentAuditLogTarget: "FILE"
      # -- idp-consent-audit.log level
      consentAuditLogLevel: "INFO"
      # -- https://github.com/GluuFederation/docker-oxshibboleth#additional-logger-configuration
      # The below are very noisy logs and are better left untouched
      ldapLogLevel: ""
      messagesLogLevel: ""
      encryptionLogLevel: ""
      opensamlLogLevel: ""
      propsLogLevel: ""
      httpclientLogLevel: ""
      springLogLevel: ""
      containerLogLevel: ""
      xmlsecLogLevel: ""
  # --  Gluu distributions supported are: default|openbanking.
  distribution: default
  persistence:
    # -- Boolean flag to enable/disable the persistence chart.
    enabled: true
  scim:
    # -- Name of the scim service. Please keep it as default.
    scimServiceName: scim
    # -- Boolean flag to enable/disable the SCIM chart.
    enabled: true
    # -- App loggers can be configured to define where the logs will be redirected to and the level of each in which it should be displayed.
    appLoggers:
      # -- Enable log prefixing which enables prepending the STDOUT logs with the file name. i.e jans-scim ===> 2022-12-20 17:49:55,744 INFO
      enableStdoutLogPrefix: "true"
      # -- jans-scim.log target
      scimLogTarget: "STDOUT"
      # -- jans-scim.log level
      scimLogLevel: "INFO"
      # -- jans-scim_persistence.log target
      persistenceLogTarget: "FILE"
      # -- jans-scim_persistence.log level
      persistenceLogLevel: "INFO"
      # -- jans-scim_persistence_duration.log target
      persistenceDurationLogTarget: "FILE"
      # -- jans-scim_persistence_duration.log level
      persistenceDurationLogLevel: "INFO"
      # -- jans-scim_persistence_ldap_statistics.log target
      ldapStatsLogTarget: "FILE"
      # -- jans-scim_persistence_ldap_statistics.log level
      ldapStatsLogLevel: "INFO"
      # -- jans-scim_script.log target
      scriptLogTarget: "FILE"
      # -- jans-scim_script.log level
      scriptLogLevel: "INFO"
    # -- Enable endpoints in either istio or nginx ingress depending on users choice
    ingress:
      # -- Enable endpoint /.well-known/scim-configuration
      scimConfigEnabled: false
      # -- Enable SCIM endpoints /jans-scim
      scimEnabled: false
  # -- StorageClass section for OpenDJ charts. This is not currently used by the openbanking distribution. You may specify custom parameters as needed.
  storageClass:
    allowVolumeExpansion: true
    allowedTopologies: []
    mountOptions:
    - debug
    # -- parameters:
    #fsType: ""
    #kind: ""
    #pool: ""
    #storageAccountType: ""
    #type: ""
    parameters: {}
    provisioner: microk8s.io/hostpath
    reclaimPolicy: Retain
    volumeBindingMode: WaitForFirstConsumer

# -- Nginx ingress definitions chart
nginx-ingress:
  certManager:
    # Enable deploying a certificate that uses dns01 challenge instead of passing an annotation nginx-ingress.ingress.additionalAnnotations for nginx http01 challenge.
    certificate:
      enabled: false
      issuerKind: ClusterIssuer
      # Issuer name which you will create manually. Can be letsencrypt-production.
      issuerName: ""
      issuerGroup: cert-manager.io
  ingress:
    # -- Admin UI ingress resource labels. key app is taken.
    adminUiLabels: { }
    # -- openid-configuration ingress resource additional annotations.
    adminUiAdditionalAnnotations: { }
    # -- openid-configuration ingress resource labels. key app is taken
    openidConfigLabels: { }
    # -- openid-configuration ingress resource additional annotations.
    openidAdditionalAnnotations: { }
    # -- device-code ingress resource labels. key app is taken
    deviceCodeLabels: { }
    # -- device-code ingress resource additional annotations.
    deviceCodeAdditionalAnnotations: { }
    # -- Firebase Messaging ingress resource labels. key app is taken
    firebaseMessagingLabels: { }
    # -- Firebase Messaging ingress resource additional annotations.
    firebaseMessagingAdditionalAnnotations: { }
    # -- uma2 config ingress resource labels. key app is taken
    uma2ConfigLabels: { }
    # -- uma2 config ingress resource additional annotations.
    uma2AdditionalAnnotations: { }
    # -- webfinger ingress resource labels. key app is taken
    webfingerLabels: { }
    # -- webfinger ingress resource additional annotations.
    webfingerAdditionalAnnotations: { }
    # -- webdiscovery ingress resource labels. key app is taken
    webdiscoveryLabels: { }
    # -- webdiscovery ingress resource additional annotations.
    webdiscoveryAdditionalAnnotations: { }
    # -- SCIM config ingress resource labels. key app is taken
    scimConfigLabels: { }
    # -- SCIM config ingress resource additional annotations.
    scimConfigAdditionalAnnotations: { }
    # -- SCIM config ingress resource labels. key app is taken
    scimLabels: { }
    # -- SCIM ingress resource additional annotations.
    scimAdditionalAnnotations: { }
    # -- configAPI ingress resource labels. key app is taken
    configApiLabels: { }
    # -- ConfigAPI ingress resource additional annotations.
    configApiAdditionalAnnotations: { }
    # -- u2f config ingress resource labels. key app is taken
    u2fConfigLabels: { }
    # -- u2f config ingress resource additional annotations.
    u2fAdditionalAnnotations: { }
    # -- fido2 config ingress resource labels. key app is taken
    fido2ConfigLabels: { }
    # -- fido2 config ingress resource additional annotations.
    fido2ConfigAdditionalAnnotations: { }
    # -- Auth server ingress resource labels. key app is taken
    authServerLabels: { }
    # -- Auth server ingress resource additional annotations.
    authServerAdditionalAnnotations: { }
    # -- Casa ingress resource labels. key app is taken
    casaLabels: { }
    # -- Casa ingress resource additional annotations.
    casaAdditionalAnnotations: { }
    # -- Auth server protected token ingress resource labels. key app is taken
    authServerProtectedTokenLabels: { }
    # -- Auth server protected token ingress resource additional annotations.
    authServerProtectedTokenAdditionalAnnotations: { }
    # -- Auth server protected token ingress resource labels. key app is taken
    authServerProtectedRegisterLabels: { }
    # -- Auth server protected register ingress resource additional annotations.
    authServerProtectedRegisterAdditionalAnnotations: { }
    # -- Additional labels that will be added across all ingress definitions in the format of {mylabel: "myapp"}
    additionalLabels: { }
    # -- Additional annotations that will be added across all ingress definitions in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
    # Enable client certificate authentication
    # nginx.ingress.kubernetes.io/auth-tls-verify-client: "optional"
    # Create the secret containing the trusted ca certificates
    # nginx.ingress.kubernetes.io/auth-tls-secret: "gluu/tls-certificate"
    # Specify the verification depth in the client certificates chain
    # nginx.ingress.kubernetes.io/auth-tls-verify-depth: "1"
    # Specify if certificates are passed to upstream server
    # nginx.ingress.kubernetes.io/auth-tls-pass-certificate-to-upstream: "true"
    additionalAnnotations: {}
    path: /
    hosts:
    - demoexample.gluu.org
    # -- Secrets holding HTTPS CA cert and key.
    tls:
    - secretName: tls-certificate
      hosts:
      - demoexample.gluu.org

# -- OpenDJ is a directory server which implements a wide range of Lightweight Directory Access Protocol and related standards, including full compliance with LDAPv3 but also support for Directory Service Markup Language (DSMLv2).Written in Java, OpenDJ offers multi-master replication, access control, and many extensions.
opendj:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: 1
  # -- Configure ldap backup cronjob
  backup:
    enabled: true
    cronJobSchedule: "*/59 * * * *"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: gluufederation/opendj
    # -- Image  tag to use for deploying.
    tag: 5.0.0-12
    # -- Image Pull Secrets
    pullSecrets: [ ]

  persistence:
    # -- OpenDJ volume size
    size: 5Gi
  ports:
    tcp-admin:
      nodePort: ""
      port: 4444
      protocol: TCP
      targetPort: 4444
    tcp-ldap:
      nodePort: ""
      port: 1389
      protocol: TCP
      targetPort: 1389
    tcp-ldaps:
      nodePort: ""
      port: 1636
      protocol: TCP
      targetPort: 1636
    tcp-repl:
      nodePort: ""
      port: 8989
      protocol: TCP
      targetPort: 8989
    tcp-serf:
      nodePort: ""
      port: 7946
      protocol: TCP
      targetPort: 7946
    udp-serf:
      nodePort: ""
      port: 7946
      protocol: UDP
      targetPort: 7946
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 1500m
      # -- Memory limit.
      memory: 2000Mi
    requests:
      # -- CPU request.
      cpu: 1500m
      # -- Memory request.
      memory: 2000Mi
  # -- Configure the liveness healthcheck for OpenDJ if needed.
  # https://github.com/GluuFederation/docker-opendj/blob/master/scripts/healthcheck.py
  livenessProbe:
    # -- Executes the python3 healthcheck.
    exec:
      command:
      - python3
      - /app/scripts/healthcheck.py
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 20
  # -- Configure the readiness healthcheck for OpenDJ if needed.
  # https://github.com/GluuFederation/docker-opendj/blob/master/scripts/healthcheck.py
  readinessProbe:
    tcpSocket:
      port: 1636
    initialDelaySeconds: 60
    timeoutSeconds: 5
    periodSeconds: 25
    failureThreshold: 20
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  lifecycle:
      preStop:
          exec:
            command: ["/bin/sh", "-c", "python3 /app/scripts/deregister_peer.py 1>&/proc/1/fd/1"]
  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Gluu interface to Passport.js to support social login and inbound identity.
oxpassport:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: gluufederation/oxpassport
    # -- Image  tag to use for deploying.
    tag: 5.0.0-12
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 700m
      # -- Memory limit.
      memory: 900Mi
    requests:
      # -- CPU request.
      cpu: 700m
      # -- Memory request.
      memory: 900Mi
  # -- Configure the liveness healthcheck for oxPassport if needed.
  livenessProbe:
    httpGet:
      # -- http liveness probe endpoint
      path: /passport/health-check
      port: http-passport
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 20
  # -- Configure the readiness healthcheck for the oxPassport if needed.
  readinessProbe:
    httpGet:
      # -- http readiness probe endpoint
      path: /passport/health-check
      port: http-passport
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
    failureThreshold: 20
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Shibboleth project for the Gluu Server's SAML IDP functionality.
oxshibboleth:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: 1
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: gluufederation/oxshibboleth
    # -- Image  tag to use for deploying.
    tag: 5.0.0-12
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit.
      cpu: 1000m
      # -- Memory limit.
      memory: 1000Mi
    requests:
      # -- CPU request.
      cpu: 1000m
      # -- Memory request.
      memory: 1000Mi
  # -- Configure the liveness healthcheck for oxshibboleth if needed.
  # https://github.com/GluuFederation/docker-oxshibboleth/blob/master/scripts/healthcheck.py
  livenessProbe:
    # -- Executes the python3 healthcheck.
    exec:
      command:
      - python3
      - /app/scripts/healthcheck.py
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 20
  # -- Configure the readiness healthcheck for the casa if needed.
  readinessProbe:
  # https://github.com/GluuFederation/docker-oxshibboleth/blob/master/scripts/healthcheck.py
  # -- Executes the python3 healthcheck.
    exec:
      command:
      - python3
      - /app/scripts/healthcheck.py
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
    failureThreshold: 20
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- Job to generate data and initial config for Gluu Server persistence layer.
persistence:
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/persistence-loader
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Resource specs.
  resources:
    limits:
      # -- CPU limit
      cpu: 300m
      # -- Memory limit.
      memory: 300Mi
    requests:
      # -- CPU request.
      cpu: 300m
      # -- Memory request.
      memory: 300Mi
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}

  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
# -- System for Cross-domain Identity Management (SCIM) version 2.0
scim:
  # -- Configure the topology spread constraints. Notice this is a map NOT a list as in the upstream API
  # https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/
  topologySpreadConstraints: {}
    # -- Define below as many constraints as needed. The key name should follow the structure tsc1, tsc2...etc.
    # Do not enter the key labelSelector in the entry/entries below as that is automatically injected by the chart
    #tsc1:
    #  maxSkew: 1
    #  minDomains: 1 # optional; beta since v1.25
    #  topologyKey: kubernetes.io/hostname
    #  whenUnsatisfiable: DoNotSchedule
    #  matchLabelKeys: [] # optional; alpha since v1.25
    #  nodeAffinityPolicy: [] # optional; alpha since v1.25
    #  nodeTaintsPolicy: [] # optional; alpha since v1.25
    #tsc2:
      #maxSkew: 1
  # -- Configure the PodDisruptionBudget
  pdb:
    enabled: true
    maxUnavailable: "90%"
  # -- Configure the HorizontalPodAutoscaler
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 50
    # -- metrics if targetCPUUtilizationPercentage is not set
    metrics: []
    # -- Scaling Policies
    behavior: {}
  # -- Add custom normal and secret envs to the service
  usrEnvs:
    # -- Add custom normal envs to the service
    # variable1: value1
    normal: {}
    # -- Add custom secret envs to the service
    # variable1: value1
    secret: {}
  # -- Add custom dns policy
  dnsPolicy: ""
  # -- Add custom dns config
  dnsConfig: {}
  image:
    # -- Image pullPolicy to use for deploying.
    pullPolicy: IfNotPresent
    # -- Image  to use for deploying.
    repository: ghcr.io/janssenproject/jans/scim
    # -- Image  tag to use for deploying.
    tag: 1.0.14-1
    # -- Image Pull Secrets
    pullSecrets: [ ]
  # -- Service replica number.
  replicas: 1
  resources:
    limits:
      # -- CPU limit.
      cpu: 1000m
      # -- Memory limit.
      memory: 1000Mi
    requests:
      # -- CPU request.
      cpu: 1000m
      # -- Memory request.
      memory: 1000Mi
  service:
    # -- The name of the scim port within the scim service. Please keep it as default.
    name: http-scim
    # -- Port of the scim service. Please keep it as default.
    port: 8080
  # -- Configure the liveness healthcheck for SCIM if needed.
  livenessProbe:
    httpGet:
      # -- http liveness probe endpoint
      path: /jans-scim/sys/health-check
      port: 8080
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 5
  # -- Configure the readiness healthcheck for the SCIM if needed.
  readinessProbe:
    httpGet:
      # -- http readiness probe endpoint
      path: /jans-scim/sys/health-check
      port: 8080
    initialDelaySeconds: 25
    periodSeconds: 25
    timeoutSeconds: 5
  # -- Configure any additional volumes that need to be attached to the pod
  volumes: []
  # -- Configure any additional volumesMounts that need to be attached to the containers
  volumeMounts: []
  # Actions on lifecycle events such as postStart and preStop
  # Example
  # lifecycle:
  #   postStart:
  #     exec:
  #       command: ["sh", "-c", "mkdir /opt/jans/jetty/jans-auth/custom/static/stylesheet/"]
  lifecycle: {}
  # -- Additional labels that will be added across the gateway in the format of {mylabel: "myapp"}
  additionalLabels: { }
  # -- Additional annotations that will be added across the gateway in the format of {cert-manager.io/issuer: "letsencrypt-prod"}
  additionalAnnotations: { }
