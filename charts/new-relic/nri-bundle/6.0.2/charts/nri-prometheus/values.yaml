# -- Override the name of the chart
nameOverride: ""
# -- Override the full name of the release
fullnameOverride: ""

# -- Name of the Kubernetes cluster monitored. Can be configured also with `global.cluster`
cluster: ""
# -- This set this license key to use. Can be configured also with `global.licenseKey`
licenseKey: ""
# -- In case you don't want to have the license key in you values, this allows you to point to a user created secret to get the key from there. Can be configured also with `global.customSecretName`
customSecretName: ""
# -- In case you don't want to have the license key in you values, this allows you to point to which secret key is the license key located. Can be configured also with `global.customSecretLicenseKey`
customSecretLicenseKey: ""

# -- Image for the New Relic Kubernetes integration
# @default -- See `values.yaml`
image:
  registry:
  repository: newrelic/nri-prometheus
  tag: ""  # Defaults to chart's appVersion
  imagePullPolicy: IfNotPresent
  # -- The secrets that are needed to pull images from a custom registry.
  pullSecrets: []
  # - name: regsecret

resources: {}
  # limits:
  #   cpu: 200m
  #   memory: 512Mi
  # requests:
  #   cpu: 100m
  #   memory: 256Mi

rbac:
  # -- Specifies whether RBAC resources should be created
  create: true

serviceAccount:
  # -- Add these annotations to the service account we create. Can be configured also with `global.serviceAccount.annotations`
  annotations: {}
  # -- Configures if the service account should be created or not. Can be configured also with `global.serviceAccount.create`
  create: true
  # -- Change the name of the service account. This is honored if you disable on this cahrt the creation of the service account so you can use your own. Can be configured also with `global.serviceAccount.name`
  name:

# -- Annotations to be added to all pods created by the integration.
podAnnotations: {}
# -- Additional labels for chart pods. Can be configured also with `global.podLabels`
podLabels: {}
# -- Additional labels for chart objects. Can be configured also with `global.labels`
labels: {}

# -- Sets pod's priorityClassName. Can be configured also with `global.priorityClassName`
priorityClassName: ""
# -- (bool) Sets pod's hostNetwork. Can be configured also with `global.hostNetwork`
# @default -- `false`
hostNetwork:
# -- Sets pod's dnsConfig. Can be configured also with `global.dnsConfig`
dnsConfig: {}

# -- Sets security context (at pod level). Can be configured also with `global.podSecurityContext`
podSecurityContext: {}
# -- Sets security context (at container level). Can be configured also with `global.containerSecurityContext`
containerSecurityContext: {}

# -- Sets pod/node affinities. Can be configured also with `global.affinity`
affinity: {}
# -- Sets pod's node selector. Can be configured also with `global.nodeSelector`
nodeSelector: {}
# -- Sets pod's tolerations to node taints. Can be configured also with `global.tolerations`
tolerations: []


# -- Provides your own `config.yaml` for this integration.
# Ref: https://docs.newrelic.com/docs/infrastructure/prometheus-integrations/install-configure-openmetrics/configure-prometheus-openmetrics-integrations/#example-configuration-file
# @default -- See `values.yaml`
config:
  # How often the integration should run.
  # Default: "30s"
  # scrape_duration: "30s"

  # The HTTP client timeout when fetching data from targets.
  # Default: "5s"
  # scrape_timeout: "5s"

  # scrape_services Allows to enable scraping the service and not the endpoints behind.
  # When endpoints are scraped this is no longer needed
  scrape_services: true

  # scrape_endpoints Allows to enable scraping directly endpoints instead of services as prometheus service natively does.
  # Please notice that depending on the number of endpoints behind a service the load can increase considerably
  scrape_endpoints: false

  # How old must the entries used for calculating the counters delta be
  # before the telemetry emitter expires them.
  # Default: "5m"
  # telemetry_emitter_delta_expiration_age: "5m"

  # How often must the telemetry emitter check for expired delta entries.
  # Default: "5m"
  # telemetry_emitter_delta_expiration_check_interval: "5m"

  # Whether the integration should run in audit mode or not. Defaults to false.
  # Audit mode logs the uncompressed data sent to New Relic. Use this to log all data sent.
  # It does not include verbose mode. This can lead to a high log volume, use with care.
  # Default: false
  audit: false

  # Whether the integration should skip TLS verification or not.
  # Default: false
  insecure_skip_verify: false

  # The label used to identify scrapeable targets.
  # Targets can be identified using a label or annotation.
  # Default: "prometheus.io/scrape"
  scrape_enabled_label: "prometheus.io/scrape"

  # Whether k8s nodes need to be labelled to be scraped or not.
  # Default: true
  require_scrape_enabled_label_for_nodes: true

  # Number of worker threads used for scraping targets.
  # For large clusters with many (>400) targets, slowly increase until scrape
  # time falls between the desired `scrape_duration`.
  # Increasing this value too much will result in huge memory consumption if too
  # many metrics are being scraped.
  # Default: 4
  # worker_threads: 4

  # Maximum number of metrics to keep in memory until a report is triggered.
  # Changing this value is not recommended unless instructed by the New Relic support team.
  # max_stored_metrics: 10000

  # Minimum amount of time to wait between reports. Cannot be lowered than the default, 200ms.
  # Changing this value is not recommended unless instructed by the New Relic support team.
  # min_emitter_harvest_period: 200ms

  # targets:
  #   - description: Secure etcd example
  #     urls: ["https://192.168.3.1:2379", "https://192.168.3.2:2379", "https://192.168.3.3:2379"]
  #     If true the Kubernetes Service Account token will be included as a Bearer token in the HTTP request.
  #     use_bearer: false
  #     tls_config:
  #       ca_file_path: "/etc/etcd/etcd-client-ca.crt"
  #       cert_file_path: "/etc/etcd/etcd-client.crt"
  #       key_file_path: "/etc/etcd/etcd-client.key"

  # Certificate to add to the root CA that the emitter will use when
  # verifying server certificates.
  # If left empty, TLS uses the host's root CA set.
  # emitter_ca_file: "/path/to/cert/server.pem"

  # Set to true in order to stop autodiscovery in the k8s cluster. It can be useful when running the Pod with a service account
  # having limited privileges.
  # Default: false
  # disable_autodiscovery: false

  # Whether the emitter should skip TLS verification when submitting data.
  # Default: false
  # emitter_insecure_skip_verify: false

  # Histogram support is based on New Relic's guidelines for higher
  # level metrics abstractions https://github.com/newrelic/newrelic-exporter-specs/blob/master/Guidelines.md.
  # To better support visualization of this data, percentiles are calculated
  # based on the histogram metrics and sent to New Relic.
  # By default, the following percentiles are calculated: 50, 95 and 99.
  #
  # percentiles:
  #   - 50
  #   - 95
  #   - 99

  transformations: []
  # - description: "Custom transformation Example"
  #   rename_attributes:
  #     - metric_prefix: ""
  #       attributes:
  #         container_name: "containerName"
  #         pod_name: "podName"
  #         namespace: "namespaceName"
  #         node: "nodeName"
  #         container: "containerName"
  #         pod: "podName"
  #         deployment: "deploymentName"
  #   ignore_metrics:
  #     # Ignore the following metrics.
  #     # These metrics are already collected by the New Relic Kubernetes Integration.
  #     - prefixes:
  #       - kube_daemonset_
  #       - kube_deployment_
  #       - kube_endpoint_
  #       - kube_namespace_
  #       - kube_node_
  #       - kube_persistentvolume_
  #       - kube_pod_
  #       - kube_replicaset_
  #       - kube_service_
  #       - kube_statefulset_
  #   copy_attributes:
  #     # Copy all the labels from the timeseries with metric name
  #     # `kube_hpa_labels` into every timeseries with a metric name that
  #     # starts with `kube_hpa_` only if they share the same `namespace`
  #     # and `hpa` labels.
  #     - from_metric: "kube_hpa_labels"
  #       to_metrics: "kube_hpa_"
  #       match_by:
  #         - namespace
  #         - hpa
  #     - from_metric: "kube_daemonset_labels"
  #       to_metrics: "kube_daemonset_"
  #       match_by:
  #         - namespace
  #         - daemonset
  #     - from_metric: "kube_statefulset_labels"
  #       to_metrics: "kube_statefulset_"
  #       match_by:
  #         - namespace
  #         - statefulset
  #     - from_metric: "kube_endpoint_labels"
  #       to_metrics: "kube_endpoint_"
  #       match_by:
  #         - namespace
  #         - endpoint
  #     - from_metric: "kube_service_labels"
  #       to_metrics: "kube_service_"
  #       match_by:
  #         - namespace
  #         - service
  #     - from_metric: "kube_node_labels"
  #       to_metrics: "kube_node_"
  #       match_by:
  #         - namespace
  #         - node

# -- (bool) Reduces number of metrics sent in order to reduce costs. Can be configured also with `global.lowDataMode`
# @default -- false
lowDataMode:

# -- Configures the integration to send all HTTP/HTTPS request through the proxy in that URL. The URL should have a standard format like `https://user:password@hostname:port`. Can be configured also with `global.proxy`
proxy: ""

# -- (bool) Send the metrics to the staging backend. Requires a valid staging license key. Can be configured also with `global.nrStaging`
# @default -- false
nrStaging:
fedramp:
  # fedramp.enabled -- (bool) Enables FedRAMP. Can be configured also with `global.fedramp.enabled`
  # @default -- false
  enabled:
# -- (bool) Sets the debug logs to this integration or all integrations if it is set globally. Can be configured also with `global.verboseLog`
# @default -- false
verboseLog:
