
{{- if (.Values.serviceAccount.hook.create) }}
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ template "px.hookServiceAccount" . }}
  namespace: {{ template "px.getDeploymentNamespace" . }}
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook": "post-install,pre-upgrade,pre-delete"
  labels:
    heritage: {{ .Release.Service }}
    release: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{.Release.Service | quote }}
    app.kubernetes.io/instance: {{.Release.Name | quote }}
    chart: "{{.Chart.Name}}-{{.Chart.Version}}"
---
kind: ClusterRole
apiVersion: {{ template "rbac.apiVersion" . }}
metadata:
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook": "post-install,pre-upgrade,pre-delete"
  name: {{ template "px.hookClusterRole" . }}
rules:
  # for daemonset to operator migration, we need hooks for all resources deployed by daemonset, due to resources are
  # different in different helm charts (GCP, IKS, Rancher and portworx), we use wild card here. After daemonset
  # migration is finished for all customers we shall change this back to limited access.
  - apiGroups: ["*"]
    resources: ["*"]
    verbs: ["*"]
---
kind: ClusterRoleBinding
apiVersion: {{ template "rbac.apiVersion" . }}
metadata:
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
    "helm.sh/hook": "post-install,pre-upgrade,pre-delete"
  name: {{ template "px.hookClusterRoleBinding" . }}
subjects:
  - kind: ServiceAccount
    name: {{ template "px.hookServiceAccount" . }}
    namespace: {{ template "px.getDeploymentNamespace" . }}
roleRef:
  kind: ClusterRole
  name: {{ template "px.hookClusterRole" . }}
  apiGroup: rbac.authorization.k8s.io
{{- end }}
