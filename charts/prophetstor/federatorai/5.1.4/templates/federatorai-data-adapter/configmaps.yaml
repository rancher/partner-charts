---
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
{{- if .Values.global.commonAnnotations }}
{{- include "render-value" ( dict "value" .Values.global.commonAnnotations "context" .) | nindent 4 }}
{{- end }}
  labels:
{{- if .Values.global.commonLabels }}
{{- include "render-value" ( dict "value" .Values.global.commonLabels "context" .) | nindent 4 }}
{{- end }}
    app.kubernetes.io/part-of: federatorai
    app: alameda
  name: federatorai-data-adapter-config
  namespace: {{ .Release.Namespace }}
data:
  telegraf.conf: |+
    [global_tags]

    [agent]
      interval = "1m"
      ## DA will try to reload user configuration periodically
      # configuration_reload_interval = "1h", DA will reload user configuration every hour
      # configuration_reload_interval = "0s", DA will disabled this feature. And DA only reload user configuration when receiving configuration change notification
      configuration_reload_interval = "$CONFIGURATION_RELOAD_INTERVAL"
      delay_query_interval = "$DELAY_QUERY_INTERVAL"
      round_interval = true
      metric_batch_size = 100000
      metric_buffer_limit = 100000
      collection_jitter = "5s"
      flush_interval = "20s"
      flush_jitter = "0s"
      precision = "1us"
      debug = $DEBUG
      aggregator_queue = 200000
      max_rpc_receive_size = $MAX_RPC_RECEIVE_SIZE
      logfile = "/var/log/telegraf.log"
      logfile_rotation_interval = "1d"
      logfile_rotation_max_archives = 10
      logfile_rotation_max_size = "200MB"
      logfile_compress_archives = true
      logfile_total_max_size = "$FEDERATORAI_MAXIMUM_LOG_SIZE"
      logfile_queue_size = $MAX_LOG_QUEUE_SIZE
      logfile_queue_trace_interval = "$LOG_QUEUE_TRACE_INTERVAL"
      logfile_enabled_async_logger = $ENABLED_ASYNC_LOGGER
      ## Data adapter will flush log queue to console if queue is full
      enable_logfile_flush_to_console = $ENABLE_FLUSH_LOG_TO_CONSOLE
      logfile_flush_to_console_level = "$LOG_FLUSH_TO_CONSOLE_LEVEL"
      ## Query will retry if some metrics hasn't returned yet.
      max_retry = 1
      retry_interval = "10s"
      max_request_line = $MAX_REQUEST_LINE
      sysdig_max_char_per_chunk = $SYSDIG_MAX_CHAR_PER_CHUNK
      # sysdig_max_query_per_chunk accepted value [1-20], default value is 10 if not setted
      sysdig_max_query_per_chunk = $SYSDIG_MAX_QUERY_PER_CHUNK
      quiet = false
      hostname = ""
      omit_hostname = false
      alamedascaler_enable = true
      enable_historical_data_collection = false
      force_reload_configuration = false
      fed_rest_url = "$FED_REST_URL"
      fed_rest_port = "$FED_REST_PORT"
      datahub_url = "$DATAHUB_URL"
      datahub_port = "$DATAHUB_PORT"
      rabbitmq_url = "$RABBITMQ_URL"
      rabbitmq_port = "$RABBITMQ_PORT"
      rabbitmq_subscriber = "data_adapter"
      expired_time = "$DATA_EXPIRED_TIME"
      cloud_metadata_expired_time = "$CLOUD_METADATA_EXPIRED_TIME"
      event_cache_expired_time = "$POST_EVENT_INTERVAL"

      ## set collect_metadata_only=false to collect resource metadata and metrics
      ## set collect_metadata_only=true to only collect resource metadata
      collect_metadata_only = $COLLECT_METADATA_ONLY

      aws_metric_list = "$AWS_METRIC_LIST"
      drop_duplicated_rest_api = true
      force_send_rest_api_time = "1h"

      # Default disable integration metrics setting
      # Cost Analysis related metrics
      cost_analysis_metrics = ["federatorai.cost_analysis.instance.cost","federatorai.cost_analysis.namespace.cost","federatorai.prediction.namespace.cost","federatorai.recommendation.instance","federatorai.cost_analysis.resource_alloc_cost.cluster","federatorai.cost_analysis.resource_alloc_cost.node","federatorai.cost_analysis.resource_alloc_cost.namespace","federatorai.cost_analysis.resource_usage_cost.cluster","federatorai.cost_analysis.resource_usage_cost.node","federatorai.cost_analysis.resource_usage_cost.namespace","federatorai.cost_analysis.cost_per_day.cluster","federatorai.cost_analysis.cost_per_day.node","federatorai.cost_analysis.cost_per_day.namespace","federatorai.cost_analysis.cost_per_week.cluster","federatorai.cost_analysis.cost_per_week.node","federatorai.cost_analysis.cost_per_week.namespace","federatorai.cost_analysis.cost_per_month.cluster","federatorai.cost_analysis.cost_per_month.node","federatorai.cost_analysis.cost_per_month.namespace","federatorai.recommendation.cost_analysis.cost_per_day.cluster","federatorai.recommendation.cost_analysis.cost_per_day.node","federatorai.recommendation.cost_analysis.cost_per_day.namespace","federatorai.recommendation.cost_analysis.cost_per_week.cluster","federatorai.recommendation.cost_analysis.cost_per_week.node","federatorai.recommendation.cost_analysis.cost_per_week.namespace","federatorai.recommendation.cost_analysis.cost_per_month.cluster","federatorai.recommendation.cost_analysis.cost_per_month.node","federatorai.recommendation.cost_analysis.cost_per_month.namespace","federatorai.cost_analysis.cost_efficiency_per_day.cluster","federatorai.cost_analysis.cost_efficiency_per_day.node","federatorai.cost_analysis.cost_efficiency_per_day.namespace","federatorai.cost_analysis.cost_efficiency_per_week.cluster","federatorai.cost_analysis.cost_efficiency_per_week.node","federatorai.cost_analysis.cost_efficiency_per_week.namespace","federatorai.cost_analysis.cost_efficiency_per_month.cluster","federatorai.cost_analysis.cost_efficiency_per_month.node","federatorai.cost_analysis.cost_efficiency_per_month.namespace","federatorai.recommendation.cost_analysis.cost_efficiency_per_day.cluster","federatorai.recommendation.cost_analysis.cost_efficiency_per_day.namespace","federatorai.recommendation.cost_analysis.cost_efficiency_per_week.cluster","federatorai.recommendation.cost_analysis.cost_efficiency_per_week.namespace","federatorai.recommendation.cost_analysis.cost_efficiency_per_month.cluster","federatorai.recommendation.cost_analysis.cost_efficiency_per_month.namespace"]

      ## Dashboard
      check_sysdig_dashboard_interval = "$CHECK_SYSDIG_DASHBOARD_INTERVAL"
      enable_sysdig_dashboard = $ENABLE_SYSDIG_DASHBOARD
      sysdig_dashboards = ["/etc/telegraf/dashboards/sysdig/kafka-overview.json", "/etc/telegraf/dashboards/sysdig/application-overview.json", "/etc/telegraf/dashboards/sysdig/cluster-overview.json"]

      ## Automation
      enable_dump_mock_data = false
      testing_mode = false
      fake_fed_server_mode = false
      configuration_mock_data_path = "/var/log/mock_server/mock_data/configuration"
      aws_mock_data_path = "/var/log/mock_server/mock_data/aws"
      azure_mock_data_path = "/var/log/mock_server/mock_data/azure"
      gcp_mock_data_path = "/var/log/mock_server/mock_data/gcp"
      datadog_mock_data_path = "/var/log/mock_server/mock_data/datadog"
      sysdig_mock_data_path = "/var/log/mock_server/mock_data/sysdig"
      prometheus_mock_data_path = "/var/log/mock_server/mock_data/prometheus"
      expected_result_path = "/var/log/mock_server/mock_data/expected_result"
      test_mode_result_path = "mock_server/mock_data/test_mode_result"

      ## Datadog tag mapping table
      # if enable_autodiscover_datadog_cluster_name_tag_key=true, agent uses datadog_default_cluster_tag_key to autodiscover cluster name tag key
      # if enable_autodiscover_datadog_cluster_name_tag_key=false, agent uses the cluster name tag key defined in agent.datadog_cluster_tag_mapping.
      enable_autodiscover_datadog_cluster_name_tag_key = true
      #DD_CLUSTER_NAME_TAG_KEYS is "cluster_name,kube_cluster_name,kube_cluster" by default.
      datadog_default_cluster_tag_keys  = "$DD_CLUSTER_NAME_TAG_KEYS"
      [agent.datadog_cluster_tag_mapping]
        # Datadog cluster name tag = ["<cluster_name>"]
        kube_cluster = []
        cluster_name = []
        kube_cluster_name = []

    ##################
    ### Processors ###
    ##################

    [[processors.filter_out]]
      order = 1
      namepass = ["kafka_topic_partition_current_offset", "kafka_consumer_group_current_offset", "node_disk_io_util", "sysdig_kafka_topic_partition_current_offset", "sysdig_kafka_consumergroup_current_offset", "prometheus_kube_pod_owner", "prometheus_kube_replicationcontroller_spec_replicas", "prometheus_kube_replicationcontroller_status_available_replicas", "prometheus_controller_replicas", "datadog_node_pod_phase", "datadog_kubernetes_pod_cpu_limit", "datadog_kubernetes_pod_memory_limit", "datadog_kubernetes_pod_cpu_requests", "datadog_kubernetes_pod_memory_requests", "datadog_kubernetes_container_cpu_limit", "datadog_kubernetes_container_memory_limit", "datadog_kubernetes_container_cpu_requests", "datadog_kubernetes_container_memory_requests", "datadog_pod_cpu_request_usage", "datadog_pod_cpu_limit_usage", "datadog_pod_memory_request", "datadog_pod_memory_limit", "sysdig_kube_pod_resource_limits_cpu_cores", "sysdig_kube_pod_resource_limits_memory_bytes", "sysdig_kube_pod_resource_requests_cpu_cores", "sysdig_kube_pod_resource_requests_memory_bytes", "sysdig_pod_cpu_limit_usage", "sysdig_pod_memory_limit", "sysdig_pod_cpu_request_usage", "sysdig_pod_memory_request","sysdig_kube_pod_status_phase"]
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kafka_topic_partition_current_offset"
        fields = ["kafka_topic_partition_current_offset"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kafka_consumergroup_current_offset"
        fields = ["kafka_consumergroup_current_offset"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "kafka_topic_partition_current_offset"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "kafka_consumer_group_current_offset"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "node_disk_io_util"
        fields = ["value"]
        aggregation_method = "set_max_value"
        max_value = 100.0
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_pod_owner"
        fields = ["owner_name"]
        aggregation_method = "trim_last_index"
        match_string = "-"
        [processors.filter_out.metric.condition]
          owner_kind = "ReplicaSet"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_pod_owner"
        fields = ["owner_name"]
        aggregation_method = "trim_last_index"
        match_string = "-"
        [processors.filter_out.metric.condition]
          owner_kind = "ReplicationController"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_replicationcontroller_spec_replicas"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_replicationcontroller_status_available_replicas"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_replicationcontroller_spec_replicas"
        fields = ["replicationcontroller"]
        aggregation_method = "trim_last_index"
        match_string = "-"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_kube_replicationcontroller_status_available_replicas"
        fields = ["replicationcontroller"]
        aggregation_method = "trim_last_index"
        match_string = "-"
      [[processors.filter_out.metric]]
        measurement_name = "prometheus_controller_replicas"
        fields = ["replicationcontroller"]
        aggregation_method = "trim_last_index"
        match_string = "-"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_node_pod_phase"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      # Drop Datadog cpu/memory limits/requests
      #     For metadata(pod, container and kafka_consumer_group)
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_pod_cpu_limit"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_pod_memory_limit"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_pod_cpu_requests"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_pod_memory_requests"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_container_cpu_limit"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_container_memory_limit"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_container_cpu_requests"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_kubernetes_container_memory_requests"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      # Drop Datadog cpu/memory limits/requests
      #     For metrics data(pod_cpu_limit, pod_cpu_request, pod_memory_limit and pod_memory_request)
      [[processors.filter_out.metric]]
        measurement_name = "datadog_pod_cpu_request_usage"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_pod_cpu_limit_usage"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_pod_memory_request"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "datadog_pod_memory_limit"
        fields = ["value"]
        aggregation_method = "drop_zero_value"
      # Drop Sysdig cpu/memory limits/requests
      #    For metadata(pod, container and kafka_consumer_group)
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kube_pod_resource_limits_cpu_cores"
        fields = ["kubernetes.pod.resourceLimits.cpuCores"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kube_pod_resource_limits_memory_bytes"
        fields = ["kubernetes.pod.resourceLimits.memBytes"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kube_pod_resource_requests_cpu_cores"
        fields = ["kubernetes.pod.resourceRequests.cpuCores"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kube_pod_resource_requests_memory_bytes"
        fields = ["kubernetes.pod.resourceRequests.memBytes"]
        aggregation_method = "drop_zero_value"
      # Drop Sysdig cpu/memory limits/requests
      #    For metrics data(pod_cpu_limit, pod_cpu_request, pod_memory_limit and pod_memory_request)
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_pod_cpu_limit_usage"
        fields = ["kubernetes.pod.resourceLimits.cpuCores"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_pod_memory_limit"
        fields = ["kubernetes.pod.resourceLimits.memBytes"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_pod_cpu_request_usage"
        fields = ["kubernetes.pod.resourceRequests.cpuCores"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_pod_memory_request"
        fields = ["kubernetes.pod.resourceRequests.memBytes"]
        aggregation_method = "drop_zero_value"
      [[processors.filter_out.metric]]
        measurement_name = "sysdig_kube_pod_status_phase"
        fields = ["kube_pod_status_phase"]
        aggregation_method = "drop_zero_value"

    ## Datadog integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["datadog_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/datadog_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["datadog_*", "alameda_*", "aws_cloudwatch_vm", "aws_cloudwatch_cluster_collection_done", "azure_virtualmachine_scale_set_vm", "azure_cluster_collection_done", "gcp_vm", "gcp_cluster_collection_done"]
      schema_file = "/etc/telegraf/schema/datadog_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["datadog_namespace_*", "datadog_node_info"]
      schema_file = "/etc/telegraf/schema/datadog_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["datadog_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/datadog_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "datadog"
      aggregator_processor = true
      namepass = ["datadog_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/datadog_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## Federation Prometheus/Prometheus integration: processors ##
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["prometheus_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/prometheus_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["prometheus_*", "alameda_*", "aws_cloudwatch_vm", "aws_cloudwatch_cluster_collection_done", "azure_virtualmachine_scale_set_vm", "azure_cluster_collection_done", "gcp_vm", "gcp_cluster_collection_done"]
      schema_file = "/etc/telegraf/schema/prometheus_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["prometheus_alameda_config_cluster_namespace", "prometheus_node_cpu_usage_seconds_total", "prometheus_node_memory_usage_bytes", "prometheus_kube_node_status_capacity_cpu_cores", "prometheus_nginx_http_average_response_time_ms", "prometheus_namespace_*"]
      schema_file = "/etc/telegraf/schema/prometheus_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["prometheus_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/prometheus_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "prometheus"
      aggregator_processor = true
      namepass = ["prometheus_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/prometheus_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## Sysdig integration: processors ##
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["sysdig_*", "alameda_*", "federatorai.kafka.consumer_lag", "federatorai.kafka.consumer_offset_rate", "federatorai.kafka.broker_offset_rate", "federatorai.prediction.kafka", "federatorai.recommendation",  "federatorai.prediction.controller", "federatorai.prediction.controller.max", "federatorai.prediction.controller.min", "federatorai.prediction.controller.avg", "federatorai.prediction.node", "federatorai.prediction.node.max", "federatorai.prediction.node.min", "federatorai.prediction.node.avg", "federatorai.resource_planning.node", "federatorai.resource_planning.controller", "federatorai.kubernetes.cpu.usage.total.node", "federatorai.kubernetes.cpu.usage.total.controller", "federatorai.kubernetes.memory.usage.node", "federatorai.kubernetes.memory.usage.controller", "federatorai.kubernetes.cpu.usage.total.node_rollup_3600sec", "federatorai.kubernetes.cpu.usage.total.controller_rollup_3600sec", "federatorai.kubernetes.memory.usage.node_rollup_3600sec", "federatorai.kubernetes.memory.usage.controller_rollup_3600sec", "federatorai.kubernetes.cpu.usage.total.node_rollup_21600sec", "federatorai.kubernetes.cpu.usage.total.controller_rollup_21600sec", "federatorai.kubernetes.memory.usage.node_rollup_21600sec", "federatorai.kubernetes.memory.usage.controller_rollup_21600sec", "federatorai.kubernetes.cpu.usage.total.node_rollup_86400sec", "federatorai.kubernetes.cpu.usage.total.controller_rollup_86400sec", "federatorai.kubernetes.memory.usage.node_rollup_86400sec", "federatorai.kubernetes.memory.usage.controller_rollup_86400sec"]
      schema_file = "/etc/telegraf/schema/sysdig_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["sysdig_*", "alameda_*", "aws_cloudwatch_vm", "aws_cloudwatch_cluster_collection_done", "azure_virtualmachine_scale_set_vm", "azure_cluster_collection_done", "gcp_vm", "gcp_cluster_collection_done"]
      schema_file = "/etc/telegraf/schema/sysdig_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["sysdig_alameda_config_cluster_namespace", "sysdig_namespace_*", "sysdig_kube_container_resource_limits_cpu_cores", "sysdig_kube_container_resource_requests_cpu_cores", "sysdig_alameda_config_namespace_metric_instance_config_info"]
      schema_file = "/etc/telegraf/schema/sysdig_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["sysdig_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/sysdig_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "sysdig"
      aggregator_processor = true
      namepass = ["sysdig_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/sysdig_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## VMware integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["vmware_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/vmware_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["vmware_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/vmware_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = [""]
      schema_file = "/etc/telegraf/schema/vmware_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["vmware_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/vmware_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "vmware"
      aggregator_processor = true
      namepass = ["vmware_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/vmware_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## AWS Cloudwatch integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["aws_cloudwatch_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/aws_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["aws_cloudwatch_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/aws_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["aws_cloudwatch_alameda_config_cluster_vm", "aws_cloudwatch_node_group_*"]
      schema_file = "/etc/telegraf/schema/aws_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["aws_cloudwatch_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/aws_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "aws"
      aggregator_processor = true
      namepass = ["aws_cloudwatch_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/aws_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## Azure integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["azure_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/azure_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["azure_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/azure_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["azure_alameda_config_cluster_vm", "azure_alameda_config_cluster_scale_set_vm", "azure_node_group_*"]
      schema_file = "/etc/telegraf/schema/azure_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["azure_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/azure_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "azure"
      aggregator_processor = true
      namepass = ["azure_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/azure_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## GCP integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["gcp_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/gcp_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["gcp_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/gcp_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["gcp_alameda_config_cluster_vm", "gcp_node_group_*"]
      schema_file = "/etc/telegraf/schema/gcp_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["gcp_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/gcp_aggregator_schema.json"
      config_file = "/etc/telegraf/schema/aggregator_config.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "gcp"
      aggregator_processor = true
      namepass = ["gcp_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/gcp_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## Datadog Dashboard integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["federatorai_datadog_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_datadog_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["federatorai_datadog_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_datadog_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["federatorai_datadog_*"]
      schema_file = "/etc/telegraf/schema/federatorai_datadog_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["federatorai_datadog_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/federatorai_datadog_aggregator_schema.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "datadog"
      aggregator_processor = true
      namepass = ["federatorai_datadog_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_datadog_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ## Sysdig Dashboard integration: processors
    [[processors.metrics_decorator]]
      order = 2
      namepass = ["federatorai_sysdig_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_sysdig_pre_metric_decorator.json"

    [[processors.metrics_grouping]]
      order = 3
      namepass = ["federatorai_sysdig_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_sysdig_grouping_rules.json"

    [[processors.metrics_decorator]]
      order = 4
      namepass = ["federatorai_sysdig_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_sysdig_post_metric_decorator.json"

    [[processors.aggregator]]
      order = 5
      namepass = ["federatorai_sysdig_*"]
      concurrent_job = 3
      schema_file = "/etc/telegraf/schema/federatorai_sysdig_aggregator_schema.json"

    [[processors.schema_mapping]]
      order = 6
      datasource = "sysdig"
      aggregator_processor = true
      namepass = ["federatorai_sysdig_*", "alameda_*"]
      schema_file = "/etc/telegraf/schema/federatorai_sysdig_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"
      ## Set default cloud information ifneeded
      enable_set_default_cloud_info_if_empty = $ENABLE_SET_DEFAULT_CLOUD_INFO_IF_EMPTY
      default_provider = "$DEFAULT_PROVIDER"
      default_region = "$DEFAULT_REGION"
      default_instance_type = "$DEFAULT_INSTANCE_TYPE"
      default_instance_id = "$DEFAULT_INSTANCE_ID"
      default_zone = "$DEFAULT_ZONE"

    ############################
    ### Input/Output Plugins ###
    ############################

    [[outputs.datadog]]
      User-Agent = "Federator.ai/4.2"
      kafka_dashboards = ["/etc/telegraf/dashboards/datadog/kafka/overview.json"]
      general_dashboards = ["/etc/telegraf/dashboards/datadog/kubernetes/application-overview.json", "/etc/telegraf/dashboards/datadog/kubernetes/cluster-overview.json", "/etc/telegraf/dashboards/datadog/cost/cost-analysis-overview.json", "/etc/telegraf/dashboards/datadog/cost/cost-management-cluster-overview.json", "/etc/telegraf/dashboards/datadog/cost/cost-management-node-overview.json", "/etc/telegraf/dashboards/datadog/cost/cost-management-namespace-overview.json"]
      enable_kafka_dashboard = $ENABLE_DD_DASHBOARD
      enable_general_dashboard = $ENABLE_DD_DASHBOARD
      namepass = ["federatorai_datadog_*"]
      namedrop= ["federatorai_datadog_cluster_collection_done"]
      metric_prefix = "federatorai_datadog_"

      [[outputs.datadog.clusters]]
        cluster_name = "cluster"
        user_agent = "Federatorai/5.0"
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        url = "https://api.datadoghq.com/api/v1/series"
        rest_url = "https://api.datadoghq.com/api/v1"

      # This pattern support federatorai.integration.status, federatorai.recommendation and federatorai.prediction.*
      [[outputs.datadog.integration_metrics]]
        name="federatorai.*"
        aggregation_type="raw"

    ## Alameda Configuration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "alameda_configuration_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0h" #Support s(second),m(minute),h(hour)
      collection_jitter = "0s"
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "alameda_datahub"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = true
      overwrite_query_delay_interval = true
      delay_query_interval = "1s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/alameda_config_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federation Prometheus integration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federation_prometheus_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: prometheus
      source = "prometheus"
      ## which collector to handle the data collection
      collector = "prometheus"
      ## account name
      account = ""
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "http://prometheus-prometheus-oper-prometheus.default.svc:9090"
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federation_prometheus_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_prometheus_config.json"
      target_label = "clusterID: cluster1"
      cluster_name = "default"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## Rancher Prometheus integration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "rancher_prometheus_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: prometheus
      source = "prometheus"
      ## which collector to handle the data collection
      collector = "prometheus"
      ## account name
      account = ""
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "http://prometheus-prometheus-oper-prometheus.default.svc:9090"
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/rancher_prometheus_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_prometheus_config.json"
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## Prometheus integration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "prometheus_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: prometheus
      source = "prometheus"
      ## which collector to handle the data collection
      collector = "prometheus"
      ## account name
      account = ""
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "http://prometheus-prometheus-oper-prometheus.default.svc:9090"
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/prometheus_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_prometheus_config.json"
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## Datadog integration: inputs.data_collector
    [[inputs.data_collector]]
      alias = "datadog_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: prometheus, datadog, sysdig
      source = "datadog"
      ## which collector to handle the data collection
      collector = "datadog"
      ## authenticated token path
      token= "${DD-API-KEY}"
      application_key = "${DD-APPLICATION-KEY}"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "https://api.datadoghq.com/api/v1/query"
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/datadog_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_datadog_config.json"
      cluster_name = "default"

    ## Sysdig integration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "sysdig_collector"
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m"
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: sysdig
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "sysdig"
      ## account name
      account = ""
      ## authenticated token path
      token= "${SYSDIG_API_TOKEN}"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "${SYSDIG_API_URL}/data/batch"
      ## Set batch query parameters
      max_query_per_chunk = $DATADOG_MAX_QUERY_PER_CHUNK
      max_characters_per_chunk = $DATADOG_MAX_CHAR_PER_CHUNK
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/sysdig_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_sysdig_config.json"
      target_label = ""
      cluster_name = "${CLUSTER_NAME}"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## VMware integration: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "vmware_metrics_collector"
      interval = "5m"
      query_start_time_offset = "-5m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: vmware
      source = "vmware"
      ## which collector to handle the data collection
      collector = "vmware"
      ## account name
      account = ""
      ## authenticated token path
      token= ""
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = "${VMWARE_API_URL}"
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/vmware_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_vmware_config.json"
      target_label = ""
      cluster_name = "${CLUSTER_NAME}"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## AWS Cloudwatch integration: inputs.data_collector
    # This plugin is for list vm in one minute
    # [[inputs.data_collector]]
    #   interval = "3m"
    #   query_start_time_offset = "-1m"
    #   query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
    #   ## data source type from which to query data
    #   ## accept values: vmware
    #   source = "aws"
    #   ## which collector to handle the data collection
    #   collector = "aws"
    #   ## account name
    #   account = ""
    #   ## authenticated token path
    #   token= ""
    #   ## TLS Insecure skip verify
    #   insecure_skip_verify = true
    #   ## one URL from which to read formatted metrics
    #   url = ""
    #   ## Load metric instance configs from Datahub or not
    #   skip_metric_instance_configs = true
    #   ## metrics schema path
    #   metric_path = ["/etc/telegraf/schema/aws_list_metrics.json"]
    #   cluster_name = "${CLUSTER_NAME}"
    #   discover_path = ""
    #   controller_name = []
    #   node_uids = []
    #   group_names = []

    ## AWS Cloudwatch integration: inputs.data_collector
    [[inputs.data_collector]]
      alias = "aws_metrics_collector"
      interval = "5m"
      query_start_time_offset = "-30m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: vmware
      source = "aws"
      ## which collector to handle the data collection
      collector = "aws"
      ## account name
      account = ""
      ## authenticated token path
      token= ""
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = ""
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/aws_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_aws_config.json"
      cluster_name = "${CLUSTER_NAME}"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## Azure integration: inputs.data_collector
    #[[inputs.data_collector]]
    #  interval = "3m"
    #  query_start_time_offset = "-1m"
    #  query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
    #  ## data source type from which to query data
    #  ## accept values: vmware
    #  source = "azure"
    #  ## which collector to handle the data collection
    #  collector = "azure"
    #  ## account name
    #  account = ""
    #  ## authenticated token path
    #  token= ""
    #  ## TLS Insecure skip verify
    #  insecure_skip_verify = true
    #  ## one URL from which to read formatted metrics
    #  url = ""
    #  ## metrics schema path
    #  metric_path = ["/etc/telegraf/schema/azure_list_metrics.json"]
    #  config_file = "/etc/telegraf/schema/collector_azure_config.json"
    #  cluster_name = "${CLUSTER_NAME}"
    #  discover_path = ""
    #  controller_name = []
    #  node_uids = []
    #  group_names = []

    ## Azure integration: inputs.data_collector
    [[inputs.data_collector]]
      alias = "azure_metrics_collector"
      interval = "5m"
      query_start_time_offset = "-10m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: vmware
      source = "azure"
      ## which collector to handle the data collection
      collector = "azure"
      ## account name
      account = ""
      ## authenticated token path
      token= ""
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = ""
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/azure_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_azure_config.json"
      cluster_name = "${CLUSTER_NAME}"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ## GCP integration: inputs.data_collector
    #[[inputs.data_collector]]
    #  interval = "3m"
    #  query_start_time_offset = "-10m"
    #  query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
    #  ## data source type from which to query data
    #  ## accept values: vmware
    #  source = "gcp"
    #  ## which collector to handle the data collection
    #  collector = "gcp"
    #  ## account name
    #  account = ""
    #  ## authenticated token path
    #  token= ""
    #  ## TLS Insecure skip verify
    #  insecure_skip_verify = true
    #  ## one URL from which to read formatted metrics
    #  url = ""
    #  ## metrics schema path
    #  metric_path = ["/etc/telegraf/schema/gcp_list_metrics.json"]
    #  config_file = "/etc/telegraf/schema/collector_gcp_config.json"
    #  cluster_name = "${CLUSTER_NAME}"
    #  discover_path = ""
    #  controller_name = []
    #  node_uids = []
    #  group_names = []

    ## GCP integration: inputs.data_collector
    [[inputs.data_collector]]
      alias = "gcp_metrics_collector"
      interval = "5m"
      query_start_time_offset = "-10m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$DATASOURCE_METRICS_RETRY_INTERVAL"
      max_retry_times = $DATASOURCE_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: vmware
      source = "gcp"
      ## which collector to handle the data collection
      collector = "gcp"
      ## account name
      account = ""
      ## authenticated token path
      token= ""
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## one URL from which to read formatted metrics
      url = ""
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/gcp_metrics.json"]
      config_file = "/etc/telegraf/schema/collector_gcp_config.json"
      cluster_name = "${CLUSTER_NAME}"
      discover_path = ""
      controller_name = []
      node_uids = []
      group_names = []

    ### Federatorai Metrics ###
    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_3_mins_aggregation_metrics_collector"
      interval = "3m"
      use_query_timestamp = true
      query_start_time_offset = "-3m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_3_mins_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_3_mins_aggregation_metrics_collector"
      interval = "3m"
      use_query_timestamp = true
      query_start_time_offset = "-3m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_3_mins_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_1_day_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "-23h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_1_day_cost_metrics_3600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_1_hour_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = true
      query_start_time_offset = "-59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_1_hour_aggregation_metrics.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_1_hour_cost_metrics_3600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_1_hour_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = true
      query_start_time_offset = "-59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_1_hour_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_7_days_costs_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "-167h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_7_days_cost_metrics_21600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_6_hours_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_6H"
      use_query_timestamp = true
      query_start_time_offset = "-5h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_6_hours_aggregation_metrics.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_6_hours_cost_metrics_21600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_6_hours_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_6H"
      use_query_timestamp = true
      query_start_time_offset = "-5h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_6_hours_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_30_days_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "-719h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_30_days_cost_metrics_86400s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_24_hours_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_24H"
      use_query_timestamp = true
      query_start_time_offset = "-23h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_24_hours_aggregation_metrics.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_24_hours_cost_metrics_86400s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_24_hours_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_24H"
      use_query_timestamp = true
      query_start_time_offset = "-23h59m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_24_hours_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_1_day_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "24h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_1_day_aggregation_metrics.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_1_day_cost_metrics_3600s.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_1_day_planning_metrics_3600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_next_1_day_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "24h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_next_1_day_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_7_days_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_6H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "168h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_7_days_aggregation_metrics.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_7_days_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "168h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_7_days_cost_metrics_21600s.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_7_days_planning_metrics_21600s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_next_7_days_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_6H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "168h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_next_7_days_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_30_days_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_24H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "720h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_30_days_aggregation_metrics.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_30_days_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "720h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = [
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_30_days_cost_metrics_86400s.json",
          "/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_30_days_planning_metrics_86400s.json"
      ]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_next_30_days_aggregation_metrics_collector"
      interval = "$COLLECTION_INTERVAL_24H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "720h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_next_30_days_aggregation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_1_min_prediction_metrics_collector"
      interval = "1m"
      use_query_timestamp = true
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_1_min_prediction_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_1_min_prediction_metrics_collector"
      interval = "1m"
      use_query_timestamp = true
      query_start_time_offset = "-1m"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_1_min_prediction_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_2_mins_observation_metrics_collector"
      interval = "1m"
      use_query_timestamp = true
      query_start_time_offset = "-2m"
      query_end_time_offset = "-1m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_2_mins_observation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Sysdig : inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_sysdig_previous_2_mins_observation_metrics_collector"
      interval = "1m"
      use_query_timestamp = true
      query_start_time_offset = "-2m"
      query_end_time_offset = "-1m" #Support s(second),m(minute),h(hour)
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "sysdig"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "10s"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_sysdig_previous_2_mins_observation_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_30_days_recommendation_instance_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "720h1m"
      query_end_time_offset = "744h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_30_days_recommendation_instance.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_previous_2_days_aggregation_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "-48h"
      query_end_time_offset = "0m" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_previous_2_days_aggregation_cost_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ## Federatorai Metrics - Datadog: inputs.data_collector ##
    [[inputs.data_collector]]
      alias = "federatorai_datadog_next_30_days_aggregation_cost_metrics_collector"
      interval = "$COLLECTION_INTERVAL_1H"
      use_query_timestamp = false
      query_start_time_offset = "1m"
      query_end_time_offset = "720h" #Support s(second),m(minute),h(hour)
      retry_interval = "$FEDERATORAI_METRICS_RETRY_INTERVAL"
      max_retry_times = $FEDERATORAI_METRICS_MAX_RETRY_TIMES
      ## data source type from which to query data
      ## accept values: alameda_datahub
      source = "datadog"
      ## which collector to handle the data collection
      collector = "alameda_datahub"
      ## authenticated token path
      token= "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## TLS Insecure skip verify
      insecure_skip_verify = true
      ## Alameda Read Configuration used
      configuration_only = false
      overwrite_query_delay_interval = true
      delay_query_interval = "$FEDERATORAI_METRIC_DELAY_QUERY_INTERVAL"
      ## one URL from which to read formatted metrics
      url = ""
      ## Load metric instance configs from Datahub or not
      skip_metric_instance_configs = true
      ## metrics schema path
      metric_path = ["/etc/telegraf/schema/federatorai_metrics/federatorai_datadog_next_30_days_aggregation_cost_metrics.json"]
      target_label = ""
      cluster_name = "default"
      discover_path = ""
      node_uids = []
      group_names = []

    ### Sync database metadata
    #[[outputs.alameda_datahub]]
    #  namedrop = ["*"]
    #  enable_sync_metadata = true
    #  sync_metadata_schema_file = "/etc/telegraf/schema/sync_metadata_schema.json"

    ## Federation Prometheus/Prometheus integration: outputs.alameda_datahub ##
    [[outputs.alameda_datahub]]
      namepass = ["prometheus_*"]
      metric_prefix = "prometheus_"
      datasource = "prometheus"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## Sysdig integration: outputs.alameda_datahub ##
    [[outputs.alameda_datahub]]
      namepass = ["sysdig_*"]
      metric_prefix = "sysdig_"
      datasource = "sysdig"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## Datadog integration: outputs.alameda_datahub ##
    [[outputs.alameda_datahub]]
      namepass = ["datadog_*"]
      metric_prefix = "datadog_"
      datasource = "datadog"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## VMware integration: outputs.alameda_datahub ##
    [[outputs.alameda_datahub]]
      namepass = ["vmware_*"]
      metric_prefix = "vmware_"
      datasource = "vmware"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## AWS Cloudwatch integration: outputs.alameda_datahub
    [[outputs.alameda_datahub]]
      namepass = ["aws_cloudwatch_*"]
      metric_prefix = "aws_cloudwatch_"
      datasource = "aws"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## Azure integration: outputs.alameda_datahub
    [[outputs.alameda_datahub]]
      namepass = ["azure_*"]
      metric_prefix = "azure_"
      datasource = "azure"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## GCP integration: outputs.alameda_datahub
    [[outputs.alameda_datahub]]
      namepass = ["gcp_*"]
      metric_prefix = "gcp_"
      datasource = "gcp"
      concurrent_job = $WRITE_DATAHUB_CONCURRENT_JOB
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    ## Post Datahub event
    [[outputs.alameda_datahub]]
      namepass = ["datahub_event"]
      metric_prefix = "datahub_"
      post_event_interval = "$POST_EVENT_INTERVAL"
      schema_file = "/etc/telegraf/schema/datahub_schema.json"
      cluster_collection_done_schema_file = "/etc/telegraf/schema/cluster_collection_done_schema.json"

    [[outputs.prometheus_client]]
      namepass = ["federatorai_sysdig_*"]
      collectors_exclude = ["gocollector", "process"]
      export_all_metrics = true
      ## Address to listen on
      listen = ":8080"
      ## Path to publish the metrics on.
      path = "/metrics"
      metric_prefix = "federatorai_sysdig_"
      expiration_interval = "5m"

    ## Test only: export DA's Prometheus metrics for automation tests
    [[outputs.prometheus_client]]
      namepass = ["prometheus_*"]
      collectors_exclude = ["gocollector", "process"]
      enable_default_value = ["prometheus_cluster", "prometheus_node", "prometheus_application", "prometheus_namespace", "prometheus_controller", "prometheus_pod", "prometheus_container", "prometheus_kafka_topic", "prometheus_kafka_consumer_group", "prometheus_nginx_web_service"]
      default_value = -1
      export_all_metrics = true
      ## Address to listen on
      listen = ":8081"
      ## Path to publish the metrics on.
      path = "/test-metrics"
      metric_prefix = ""
      expiration_interval = "5m"

    ## Test only: export DA's Datadog metrics for automation tests
    [[outputs.prometheus_client]]
      namepass = ["datadog_*", "federatorai_datadog_*"]
      collectors_exclude = ["gocollector", "process"]
      enable_default_value = ["datadog_cluster", "datadog_node", "datadog_application", "datadog_namespace", "datadog_controller", "datadog_pod", "datadog_container", "datadog_kafka_topic", "datadog_kafka_consumer_group", "datadog_nginx_web_service"]
      default_value = -1
      export_all_metrics = true
      ## Address to listen on
      listen = ":8082"
      ## Path to publish the metrics on.
      path = "/test-metrics"
      metric_prefix = "federatorai_datadog_"
      expiration_interval = "5m"

    ## Test only: export DA's Sysdig metrics for automation tests
    [[outputs.prometheus_client]]
      namepass = ["sysdig_*", "federatorai_sysdig_*"]
      collectors_exclude = ["gocollector", "process"]
      enable_default_value = ["sysdig_cluster", "sysdig_node", "sysdig_application", "sysdig_namespace", "sysdig_controller", "sysdig_pod", "sysdig_container", "sysdig_kafka_topic", "sysdig_kafka_consumer_group", "sysdig_nginx_web_service"]
      default_value = -1
      export_all_metrics = true
      ## Address to listen on
      listen = ":8083"
      ## Path to publish the metrics on.
      path = "/test-metrics"
      metric_prefix = "federatorai_sysdig_"
      expiration_interval = "5m"

    ## Export DA's metrics for health status check and performance analysis
    [[inputs.data_adapter_statistics]]
      datahub_enable = true
      aws_enable = true
      prometheus_enable = true
      sysdig_enable = true
      vmware_enable = true
      datadog_enable = true
    [[outputs.prometheus_client]]
      namepass = ["federatorai_data_adapter_datasource_*"]
      collectors_exclude = ["gocollector", "process"]
      default_value = -1
      export_all_metrics = true
      ## Address to listen on
      listen = ":8084"
      ## Path to publish the metrics on.
      path = "/test-metrics"
      expiration_interval = "5m"
